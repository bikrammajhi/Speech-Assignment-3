{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 21:52:49 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (ssl_model): SSLModel(\n",
       "      (model): Wav2Vec2Model(\n",
       "        (feature_extractor): ConvFeatureExtractionModel(\n",
       "          (conv_layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-4): 4 x Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (5-6): 2 x Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "        (dropout_features): Dropout(p=0.0, inplace=False)\n",
       "        (quantizer): GumbelVectorQuantizer(\n",
       "          (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "        )\n",
       "        (project_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (encoder): TransformerEncoder(\n",
       "          (pos_conv): Sequential(\n",
       "            (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "            (1): SamePad()\n",
       "            (2): GELU(approximate='none')\n",
       "          )\n",
       "          (layers): ModuleList(\n",
       "            (0-23): 24 x TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (final_proj): Linear(in_features=1024, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (LL): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (first_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.5, inplace=True)\n",
       "    (drop_way): Dropout(p=0.2, inplace=True)\n",
       "    (selu): SELU(inplace=True)\n",
       "    (encoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (conv_downsample): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (GAT_layer_S): GraphAttentionLayer(\n",
       "      (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (GAT_layer_T): GraphAttentionLayer(\n",
       "      (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (pool_S): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_T): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hS1): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hT1): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hS2): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hT2): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# Load the SSL W2V model trained for LA and DF tracks\n",
    "from model import Model\n",
    "\n",
    "model = Model(None, device=device)\n",
    "model = nn.DataParallel(model).to(device)\n",
    "model.load_state_dict(torch.load('finetuned_model.pth'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, max_len=64600):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len)+1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\t\n",
    "\n",
    "# Define a function to preprocess the audio samples\n",
    "def preprocess_audio(audio_path):\n",
    "    # Check file extension\n",
    "    _, ext = os.path.splitext(audio_path)\n",
    "    if ext.lower() not in ('.mp3', '.wav'):\n",
    "        # Skip processing if file extension is not .mp3 or .wav\n",
    "        return None\n",
    "    \n",
    "    # Load the audio file and extract features\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "    audio = pad(audio)\n",
    "    # Here you can apply further preprocessing if needed, e.g., feature extraction\n",
    "    return audio\n",
    "\n",
    "\n",
    "# Define paths to real and fake audio samples\n",
    "real_audio_dir = r\"Dataset_Speech_Assignment/Real\"\n",
    "fake_audio_dir = r\"Dataset_Speech_Assignment/Fake\"\n",
    "\n",
    "# Collect paths to real and fake audio files\n",
    "real_audio_paths = [os.path.join(real_audio_dir, filename) for filename in os.listdir(real_audio_dir)]\n",
    "fake_audio_paths = [os.path.join(fake_audio_dir, filename) for filename in os.listdir(fake_audio_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 200/301 [00:07<00:03, 30.52it/s]/tmp/ipykernel_73267/693797228.py:19: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_path, sr=None)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 68%|██████▊   | 205/301 [00:07<00:02, 33.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/ayla_ja.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 218/301 [00:07<00:02, 36.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/carla_pt.wav: \n",
      "Error processing Dataset_Speech_Assignment/Fake/carla_en.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 238/301 [00:08<00:02, 30.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/carla_de.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 246/301 [00:08<00:01, 31.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/ayla_en.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 258/301 [00:09<00:01, 31.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/ayla_fr.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:10<00:00, 27.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.16505847953216374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Collect predictions and ground truth labels\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "# Use tqdm to add a progress bar\n",
    "for audio_path in tqdm(real_audio_paths + fake_audio_paths):\n",
    "    try:\n",
    "        processed_audio = preprocess_audio(audio_path)\n",
    "        \n",
    "        # Skip processing if preprocess_audio returns None\n",
    "        if processed_audio is None:\n",
    "            continue\n",
    "        \n",
    "        processed_audio_tensor = torch.tensor(processed_audio, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(processed_audio_tensor)\n",
    "            # Move the tensor from CUDA device to CPU\n",
    "            output_cpu = output.cpu()\n",
    "\n",
    "            # Extract the second value (index 1) and convert it to a Python scalar\n",
    "            prediction = output_cpu[0][1].item()\n",
    "            \n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # Add ground truth label\n",
    "        if audio_path in real_audio_paths:\n",
    "            ground_truth.append(0)  # 0 for real\n",
    "        else:\n",
    "            ground_truth.append(1)  # 1 for fake\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(ground_truth, predictions)\n",
    "\n",
    "print(\"AUC:\", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.16505847953216374\n",
      "EER: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(ground_truth, predictions)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, _ = roc_curve(ground_truth, predictions)\n",
    "\n",
    "# Find the point on the ROC curve where FPR equals 1 - TPR\n",
    "eer = 1.0\n",
    "for i in range(len(fpr)):\n",
    "    if fpr[i] >= 1 - tpr[i]:\n",
    "        eer = fpr[i]\n",
    "        break\n",
    "\n",
    "# Analyze the performance of the model\n",
    "print(\"AUC:\", auc_score)\n",
    "print(\"EER:\", eer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
