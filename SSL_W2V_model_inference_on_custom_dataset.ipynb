{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# def extract_zip(zip_file, extract_to):\n",
    "#     with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(extract_to)\n",
    "#     print(\"Extraction complete.\")\n",
    "\n",
    "# # Replace 'your_zip_file.zip' with the name of your zip file\n",
    "# zip_file = 'Dataset_Speech_Assignment.zip'\n",
    "\n",
    "# # Replace 'your_extraction_directory' with the directory where you want to extract the files\n",
    "# extract_to = r'/mnt/c/Users/Manish/Desktop/SpeechAssign3/SSL_Anti-spoofing/Dataset1'\n",
    "\n",
    "# # Create the extraction directory if it doesn't exist\n",
    "# os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# # Extract the zip file\n",
    "# extract_zip(zip_file, extract_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.17.1+cu121)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.26.2)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: matplotlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.1.4)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting triton==2.2.0 (from torch)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.10.2-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.0/260.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.1/385.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: triton, soxr, nvidia-nccl-cu12, msgpack, llvmlite, lazy-loader, audioread, soundfile, pooch, numba, torch, librosa\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.3.0\n",
      "    Uninstalling triton-2.3.0:\n",
      "      Successfully uninstalled triton-2.3.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.3.0 requires torch==2.3.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2 llvmlite-0.42.0 msgpack-1.0.8 numba-0.59.1 nvidia-nccl-cu12-2.19.3 pooch-1.8.1 soundfile-0.12.1 soxr-0.3.7 torch-2.2.1 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision numpy scipy matplotlib scikit-learn pandas librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install protobuf==3.20 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 18:00:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (ssl_model): SSLModel(\n",
       "      (model): Wav2Vec2Model(\n",
       "        (feature_extractor): ConvFeatureExtractionModel(\n",
       "          (conv_layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-4): 4 x Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (5-6): 2 x Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "        (dropout_features): Dropout(p=0.0, inplace=False)\n",
       "        (quantizer): GumbelVectorQuantizer(\n",
       "          (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "        )\n",
       "        (project_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (encoder): TransformerEncoder(\n",
       "          (pos_conv): Sequential(\n",
       "            (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "            (1): SamePad()\n",
       "            (2): GELU(approximate='none')\n",
       "          )\n",
       "          (layers): ModuleList(\n",
       "            (0-23): 24 x TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (final_proj): Linear(in_features=1024, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (LL): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (first_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.5, inplace=True)\n",
       "    (drop_way): Dropout(p=0.2, inplace=True)\n",
       "    (selu): SELU(inplace=True)\n",
       "    (encoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (conv_downsample): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (GAT_layer_S): GraphAttentionLayer(\n",
       "      (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (GAT_layer_T): GraphAttentionLayer(\n",
       "      (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (pool_S): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_T): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hS1): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hT1): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hS2): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hT2): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# Load the SSL W2V model trained for LA and DF tracks\n",
    "from model import Model\n",
    "\n",
    "model = Model(None, device=device)\n",
    "model = nn.DataParallel(model).to(device)\n",
    "model.load_state_dict(torch.load('Best_LA_model_for_DF.pth'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, max_len=64600):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len)+1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\t\n",
    "\n",
    "# Define a function to preprocess the audio samples\n",
    "def preprocess_audio(audio_path):\n",
    "    # Check file extension\n",
    "    _, ext = os.path.splitext(audio_path)\n",
    "    if ext.lower() not in ('.mp3', '.wav'):\n",
    "        # Skip processing if file extension is not .mp3 or .wav\n",
    "        return None\n",
    "    \n",
    "    # Load the audio file and extract features\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "    audio = pad(audio)\n",
    "    # Here you can apply further preprocessing if needed, e.g., feature extraction\n",
    "    return audio\n",
    "\n",
    "\n",
    "# Define paths to real and fake audio samples\n",
    "real_audio_dir = r\"Dataset_Speech_Assignment/Real\"\n",
    "fake_audio_dir = r\"Dataset_Speech_Assignment/Fake\"\n",
    "\n",
    "# Collect paths to real and fake audio files\n",
    "real_audio_paths = [os.path.join(real_audio_dir, filename) for filename in os.listdir(real_audio_dir)]\n",
    "fake_audio_paths = [os.path.join(fake_audio_dir, filename) for filename in os.listdir(fake_audio_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_audio_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 197/301 [00:05<00:03, 31.94it/s]/tmp/ipykernel_1737/693797228.py:19: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_path, sr=None)\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 68%|██████▊   | 206/301 [00:06<00:02, 33.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/ayla_ja.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 219/301 [00:06<00:02, 36.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/carla_pt.wav: \n",
      "Error processing Dataset_Speech_Assignment/Fake/carla_en.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 240/301 [00:07<00:01, 32.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/carla_de.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 249/301 [00:07<00:01, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/ayla_en.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 261/301 [00:07<00:01, 33.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset_Speech_Assignment/Fake/ayla_fr.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:09<00:00, 32.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.3576023391812866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Collect predictions and ground truth labels\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "# Use tqdm to add a progress bar\n",
    "for audio_path in tqdm(real_audio_paths + fake_audio_paths):\n",
    "    try:\n",
    "        processed_audio = preprocess_audio(audio_path)\n",
    "        \n",
    "        # Skip processing if preprocess_audio returns None\n",
    "        if processed_audio is None:\n",
    "            continue\n",
    "        \n",
    "        processed_audio_tensor = torch.tensor(processed_audio, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(processed_audio_tensor)\n",
    "            # Move the tensor from CUDA device to CPU\n",
    "            output_cpu = output.cpu()\n",
    "\n",
    "            # Extract the second value (index 1) and convert it to a Python scalar\n",
    "            prediction = output_cpu[0][1].item()\n",
    "            \n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # Add ground truth label\n",
    "        if audio_path in real_audio_paths:\n",
    "            ground_truth.append(0)  # 0 for real\n",
    "        else:\n",
    "            ground_truth.append(1)  # 1 for fake\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "ground_truth = np.array(ground_truth)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(ground_truth, predictions)\n",
    "\n",
    "print(\"AUC:\", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.3576023391812866\n",
      "EER: 0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(ground_truth, predictions)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, _ = roc_curve(ground_truth, predictions)\n",
    "\n",
    "# Find the point on the ROC curve where FPR equals 1 - TPR\n",
    "eer = 1.0\n",
    "for i in range(len(fpr)):\n",
    "    if fpr[i] >= 1 - tpr[i]:\n",
    "        eer = fpr[i]\n",
    "        break\n",
    "\n",
    "# Analyze the performance of the model\n",
    "print(\"AUC:\", auc_score)\n",
    "print(\"EER:\", eer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
